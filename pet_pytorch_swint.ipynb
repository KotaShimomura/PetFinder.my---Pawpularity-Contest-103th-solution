{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8bcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../ConvNeXt')\n",
    "import models.convnext\n",
    "import models.convnext_isotropic\n",
    "import utils\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#general\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import cv2\n",
    "gc.enable()\n",
    "import glob\n",
    "pd.set_option('display.max_columns', None) \n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# augmentation\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "\n",
    "# deep learning\n",
    "import timm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau, StepLR, LambdaLR\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Random Seed Initialize\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def seed_everything(seed=RANDOM_SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "# Device Optimization\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a38da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    model_name = \"swint_large224\"\n",
    "    base_dir = \"/content/drive/MyDrive/petfinder\"\n",
    "    data_dir = '../petfin/petfinder-pawpularity-score'\n",
    "    meta_data_dir = \"../input/trainmeta/\"\n",
    "    model_dir = \".\"\n",
    "    output_dir = \".\"\n",
    "    img_train_dir = os.path.join(data_dir, \"train\")\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    random_seed = 555\n",
    "    n_epoch = 5\n",
    "    n_fold = 10\n",
    "    tta = True # calculate cv score in case TTA is executed\n",
    "    tta_times = 4\n",
    "    tta_beta = 1 / tta_times\n",
    "    model_path = \"swin_large_patch4_window7_224\"\n",
    "    model_filepath = \"../petfin/convnext_large_22k_1k_384.pth\"\n",
    "    pretrained = True\n",
    "    inp_channels = 3\n",
    "    im_size =  224\n",
    "    lr = 2e-5\n",
    "    opt_wd_non_norm_bias = 0.01\n",
    "    opt_wd_norm_bias = 0\n",
    "    opt_beta1 = 0.9\n",
    "    opt_beta2 = 0.99\n",
    "    opt_eps = 1e-5\n",
    "    batch_size = 32 #train\n",
    "    #batch_size = 128 #infer\n",
    "    epoch_step_valid = 3\n",
    "    steps_per_epoch = 62\n",
    "    num_workers = 0\n",
    "    out_features = 1\n",
    "    dense_features = ['is_cat']\n",
    "    dropout = 0\n",
    "    aug_decay_epoch = 4\n",
    "    mixup = False\n",
    "    if mixup:\n",
    "        mixup_epoch = n_epoch\n",
    "    else:\n",
    "        mixup_epoch = 0\n",
    "    mixup_alpha =0.2\n",
    "    scheduler_name = \"OneCycleLR\" #OneCycleLR\n",
    "    reduce_lr_factor = 0.6\n",
    "    reduce_lr_patience = 1\n",
    "    T_0 = 4 \n",
    "    T_max =4\n",
    "    T_mult =1\n",
    "    min_lr = 1e-7\n",
    "    max_lr =2e-5\n",
    "    is_debug = False\n",
    "#     is_debug = True\n",
    "    if is_debug:\n",
    "        n_epoch = 1\n",
    "        aug_decay_epoch = 1\n",
    "        n_fold = 2\n",
    "        n_sample_debug = 500\n",
    "        tta_times = 2\n",
    "        tta_beta = 1 / tta_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet =['crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b67774",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../petfin/archive/'\n",
    "image_directory = {}\n",
    "for i in pet:\n",
    "    image_directory[i] = [os.path.join(path,i,j) for j in  os.listdir(os.path.join(path,i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_category = []\n",
    "file_name = []\n",
    "for i in image_directory.keys():\n",
    "    for j in image_directory[i]:\n",
    "        file_category.append(i)\n",
    "        file_name.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'categories':file_category,'file_name':file_name}\n",
    "image_df = pd.DataFrame(data)\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9560f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists('../petfin/output/checkpoints/'):\n",
    "#    os.makedirs('../petfin/output/checkpoints/')\n",
    "#!cp '../petfin/swin_large_patch4_window12_384_22kto1k.pth' '../petfin/output/checkpoints/swin_large_patch4_window12_384_22kto1k.pth'\n",
    "#!cp '../petfin/swin_large_patch4_window7_224_22kto1k.pth' '../petfin/output/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_dir = os.path.join(Config.data_dir, 'train')\n",
    "def return_imgfilepath(name, folder=img_train_dir):\n",
    "    path = os.path.join(folder, f'{name}.jpg')\n",
    "    return path\n",
    "\n",
    "#train_file_path = os.path.join(Config.data_dir, 'train.csv')\n",
    "#train_df = pd.read_csv(train_file_path)\n",
    "train_df = pd.read_csv('train_add_f.csv')\n",
    "#train_df = pd.read_pickle('train.pkl')\n",
    "\n",
    "# set image filepath\n",
    "train_df['file_path'] = train_df['Id'].progress_apply(lambda x: return_imgfilepath(x))\n",
    "#train_df['file_path'] = image_df['file_name']\n",
    "\n",
    "#categorical_columns = ['label']\n",
    "#train_df = pd.get_dummies(train_df, columns=categorical_columns)\n",
    "#train_df = train_df.rename(columns={'label_cat': 'cat','label_dog' : 'dog', 'label_unknown': 'neither'})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.is_debug:\n",
    "    train_df = train_df.sample(500).reset_index(drop = True)\n",
    "train_df['norm_score'] = train_df['Pawpularity'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4227626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sturges' rule\n",
    "num_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n",
    "#num_bins = int(np.floor(1+np.log2(len(train_df))))\n",
    "#num_bins = int(np.ceil(2*((len(train_df))**(1./3))))\n",
    "train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\n",
    "train_df['fold'] = -1\n",
    "\n",
    "skf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state =Config.random_seed)\n",
    "for i, (_, train_index) in enumerate(skf.split(train_df.index, train_df['bins'])):\n",
    "    train_df.iloc[train_index, -1] = i\n",
    "    \n",
    "train_df['fold'] = train_df['fold'].astype('int')\n",
    "\n",
    "train_df.fold.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['fold']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, dense_features, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "        image = np.array(image_rgb)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]\n",
    "        \n",
    "        image = image / 255 # convert to 0-1\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        dense = self.dense_features[idx, :]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype = torch.float)\n",
    "        dense = torch.tensor(dense, dtype = torch.float)\n",
    "        target = torch.tensor(target, dtype = torch.float)\n",
    "        return image, dense, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "# calculated mean & std\n",
    "# IMAGENET_MEAN=[0.51876384, 0.48398507, 0.44618937],\n",
    "# IMAGENET_STD=[0.26810414, 0.26382494, 0.26581845],\n",
    "\n",
    "def get_train_transforms(epoch, dim = Config.im_size):\n",
    "    return A.Compose(\n",
    "        [             \n",
    "            # resize like Resize in fastai\n",
    "            A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "            A.RandomCrop(height=dim, width=dim, p=1.0),\n",
    "            A.VerticalFlip(p = 0.5),\n",
    "            A.HorizontalFlip(p = 0.5),\n",
    "            # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        ]\n",
    "  )\n",
    "\n",
    "def get_inference_fixed_transforms(mode=0, dim = Config.im_size):\n",
    "    if mode == 0: # do not original aspects, colors and angles\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ], p=1.0)\n",
    "    elif mode == 1:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                A.VerticalFlip(p = 1.0)\n",
    "            ], p=1.0)    \n",
    "    elif mode == 2:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                A.HorizontalFlip(p = 1.0)\n",
    "            ], p=1.0)\n",
    "    elif mode == 3:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                A.Transpose(p=1.0)\n",
    "            ], p=1.0)\n",
    "    \n",
    "def get_inference_random_transforms(mode=0, dim = Config.im_size):\n",
    "    if mode == 0: # do not original aspects, colors and angles\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ], p=1.0)\n",
    "    else:\n",
    "        return A.Compose(\n",
    "            [            \n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                A.VerticalFlip(p = 0.5),\n",
    "                A.HorizontalFlip(p = 0.5),\n",
    "                # A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, Config, device):\n",
    "    if Config.mixup_alpha > 0:\n",
    "        lam = np.random.beta(\n",
    "            Config.mixup_alpha, Config.mixup_alpha\n",
    "        )\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if device == 'cuda':\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ec931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with meta\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name=Config.model_path, \n",
    "                 out_features=Config.out_features, inp_channels=Config.inp_channels,\n",
    "                 pretrained=Config.pretrained, num_dense=len(Config.dense_features)):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n",
    "        n_features = self.model.head.in_features\n",
    "        self.model.head = nn.Linear(n_features, 128)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + num_dense, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, out_features)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(Config.dropout)\n",
    "    \n",
    "    def forward(self, image, dense):\n",
    "        embeddings = self.model(image)\n",
    "        x = self.dropout(embeddings)\n",
    "        x = torch.cat([x, dense], dim=1)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# class PetNet(nn.Module):\n",
    "#     def __init__(self, model_arch, n_class=1, in_channels=3, pretrained_path=''):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_arch, in_chans=in_channels, pretrained=False)\n",
    "#         self.model=self.load_pretrain(self.model,pretrained_path)\n",
    "#         num_ftrs = self.model.head.in_features\n",
    "#         self.model.head = nn.Linear(num_ftrs, n_class)\n",
    "#     def load_pretrain(self,model,pretrained_path):\n",
    "#         checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "#         print(\"Load ckpt from %s\" % pretrained_path)\n",
    "#         checkpoint_model = checkpoint['model']\n",
    "#         state_dict = model.state_dict()\n",
    "#         for k in ['head.weight', 'head.bias']:\n",
    "#             if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "#                 print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "#                 del checkpoint_model[k]\n",
    "#         utils.load_state_dict(model, checkpoint_model, prefix='')\n",
    "#         return model\n",
    "#     def forward(self, x):\n",
    "#         x = self.model(x)\n",
    "#         x=x.flatten()\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divice_norm_bias(model): \n",
    "    norm_bias_params = []\n",
    "    non_norm_bias_params = []\n",
    "    except_wd_layers = ['norm', '.bias']\n",
    "    for n, p in model.model.named_parameters():\n",
    "        if any([nd in n for nd in except_wd_layers]):\n",
    "            norm_bias_params.append(p)\n",
    "        else:\n",
    "            non_norm_bias_params.append(p)\n",
    "    return norm_bias_params, non_norm_bias_params\n",
    "\n",
    "def usr_rmse_score(output, target):\n",
    "    y_pred = torch.sigmoid(output).cpu()\n",
    "    y_pred = y_pred.detach().numpy()*100\n",
    "    target = target.cpu()*100\n",
    "    \n",
    "    return mean_squared_error(target, y_pred, squared=False)\n",
    "\n",
    "def rmse_oof(_oof_df, fold=None):\n",
    "    oof_df = _oof_df.copy()\n",
    "    if fold is not None:\n",
    "        oof_df = oof_df[oof_df[\"fold\"] == fold]\n",
    "    target = oof_df['Pawpularity'].values\n",
    "    y_pred = oof_df['pred'].values\n",
    "    if fold is not None:\n",
    "        print(f'fold {fold}: {mean_squared_error(target, y_pred, squared=False)}')\n",
    "    else:\n",
    "        print(f'overall: {mean_squared_error(target, y_pred, squared=False)}')\n",
    "\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"],\n",
    "                    float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c318fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer):\n",
    "    scheduler = None\n",
    "    if Config.scheduler_name == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=Config.T_0,\n",
    "            eta_min=Config.min_lr,\n",
    "            last_epoch=-1\n",
    "        )\n",
    "    elif Config.scheduler_name == 'OneCycleLR':\n",
    "        # div=25\n",
    "        # initial_lr =max_lr/div\n",
    "        # default last_lr =initial lr / final_div_factor(10000) = max_lr \n",
    "        # in case fastai  default last_lr =max_lr / div_final(100000)\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=Config.max_lr,\n",
    "            pct_start = 0.25, # same as fastai, defaut 0.3\n",
    "            steps_per_epoch=int(((Config.n_fold - 1) * train_df.shape[0]) / (Config.n_fold * Config.batch_size)) + 1,\n",
    "            epochs = Config.n_epoch\n",
    "        )\n",
    "\n",
    "    elif Config.scheduler_name == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=Config.T_max,\n",
    "            eta_min=Config.min_lr,\n",
    "            last_epoch=-1\n",
    "        )\n",
    "    elif Config.scheduler_name == 'ReduceOnPlateauLR':\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode = 'min',\n",
    "            factor=Config.reduce_lr_factor,\n",
    "            patience=Config.reduce_lr_patience,\n",
    "            verbose = True\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(y_valid, X_valid_paths, X_valid_dense, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    #model = layer_freeze(model)\n",
    "    tta_mode = 0\n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    valid_dataset = PetDataset(\n",
    "      image_filepaths = X_valid_paths,\n",
    "      dense_features = X_valid_dense,\n",
    "      targets = y_valid,\n",
    "      transform = get_inference_fixed_transforms(tta_mode)\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "      valid_dataset,\n",
    "      batch_size = Config.batch_size,\n",
    "      shuffle = False,\n",
    "      num_workers = Config.num_workers,\n",
    "      pin_memory = True\n",
    "    )\n",
    "    metric_monitor = MetricMonitor()\n",
    "    stream = tqdm(valid_loader)\n",
    "    for i, (images, dense, target) in enumerate(stream, start = 1):\n",
    "        images = images.to(device, non_blocking = True).float()\n",
    "        dense = dense.to(device, non_blocking = True).float()\n",
    "        target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            output = model(images, dense)\n",
    "        loss = criterion(output, target)\n",
    "        rmse_score = usr_rmse_score(output, target)\n",
    "        metric_monitor.update('Loss', loss.item())\n",
    "        metric_monitor.update('RMSE', rmse_score)\n",
    "        stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n",
    "\n",
    "        targets = (target.detach().cpu().numpy() * 100).ravel().tolist()\n",
    "        pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n",
    "\n",
    "        test_preds.extend(pred)\n",
    "        test_targets.extend(targets)\n",
    "    test_preds = np.array(test_preds)\n",
    "    test_targets = np.array(test_targets)\n",
    "    del valid_loader, valid_dataset, target, output\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return test_targets, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d86d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_fn(y_valid, X_valid_paths, X_valid_dense, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    #model = layer_freeze(model)\n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    for tta_mode in range(Config.tta_times):\n",
    "        print(f'tta mode:{tta_mode}')\n",
    "        valid_dataset = PetDataset(\n",
    "          image_filepaths = X_valid_paths,\n",
    "          dense_features = X_valid_dense,\n",
    "          targets = y_valid,\n",
    "          transform = get_inference_fixed_transforms(tta_mode)\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "          valid_dataset,\n",
    "          batch_size = Config.batch_size,\n",
    "          shuffle = False,\n",
    "          num_workers = Config.num_workers,\n",
    "          pin_memory = True\n",
    "        )\n",
    "        metric_monitor = MetricMonitor()\n",
    "        stream = tqdm(valid_loader)\n",
    "        tta_preds = []\n",
    "        for i, (images, dense, target) in enumerate(stream, start = 1):\n",
    "            images = images.to(device, non_blocking = True).float()\n",
    "            dense = dense.to(device, non_blocking = True).float()\n",
    "            target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "            with torch.no_grad():\n",
    "                output = model(images, dense)\n",
    "\n",
    "            targets = (target.detach().cpu().numpy() * 100).ravel().tolist()\n",
    "            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n",
    "            loss = criterion(output, target)\n",
    "            rmse_score = usr_rmse_score(output, target)\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('RMSE', rmse_score)\n",
    "            stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n",
    "\n",
    "            tta_preds.extend(pred)\n",
    "            if tta_mode == 0:\n",
    "                test_targets.extend(targets)\n",
    "        test_preds.append(tta_preds)\n",
    "    test_preds = np.array(test_preds)\n",
    "    # default preds * tta_beta + aug_preds mean * ( 1 - tta_beta)\n",
    "    #print(test_preds.shape)\n",
    "    final_preds = Config.tta_beta * test_preds[0] + ( 1 - Config.tta_beta) * np.mean(test_preds[1:], axis =0)\n",
    "    test_targets = np.array(test_targets)\n",
    "    del valid_loader, valid_dataset, target, output\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return test_targets, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(filepaths, dense_features, targets):\n",
    "    skf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\n",
    "    oof_df = pd.DataFrame()\n",
    "    for i_fold, (train_idx, valid_idx) in enumerate(skf.split(filepaths, target_bins)):\n",
    "        print(f'=== fold {i_fold}: training ===')\n",
    "        \"\"\"\n",
    "        separate train/valid data \n",
    "        \"\"\"\n",
    "        X_train_paths = filepaths[train_idx]\n",
    "        X_train_dense = dense_features[train_idx]\n",
    "        y_train = targets[train_idx]\n",
    "        X_valid_paths = filepaths[valid_idx]\n",
    "        X_valid_dense = dense_features[valid_idx]\n",
    "        y_valid = targets[valid_idx]\n",
    "        valid_ids = ids[valid_idx]\n",
    "        \"\"\"\n",
    "        prepare dataset\n",
    "        \"\"\"\n",
    "        train_dataset = PetDataset(\n",
    "          image_filepaths = X_train_paths,\n",
    "          dense_features = X_train_dense,\n",
    "          targets = y_train,\n",
    "          transform = get_train_transforms(0)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        create dataloader\n",
    "        \"\"\"\n",
    "        train_loader = DataLoader(\n",
    "          train_dataset,\n",
    "          batch_size = Config.batch_size,\n",
    "          shuffle = True,\n",
    "          num_workers = Config.num_workers,\n",
    "          pin_memory = True\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        instantiate model, cost function and optimizer\n",
    "        \"\"\"\n",
    "        model = PetNet()\n",
    "        model = model.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n",
    "        #print(f\"norm bias params: {len(norm_bias_params)}, non norm bias params: {len(non_norm_bias_params)}\")\n",
    "        optimizer = torch.optim.AdamW(\n",
    "          [\n",
    "              {'params': norm_bias_params, 'weight_decay': Config.opt_wd_norm_bias},\n",
    "              {'params': non_norm_bias_params, 'weight_decay': Config.opt_wd_non_norm_bias},\n",
    "          ],\n",
    "          betas=(Config.opt_beta1, Config.opt_beta2),\n",
    "          eps=Config.opt_eps,\n",
    "          lr = Config.lr,\n",
    "          amsgrad = False\n",
    "        )\n",
    "        scheduler = get_scheduler(optimizer)\n",
    "        \"\"\"\n",
    "        train / valid loop\n",
    "        \"\"\"\n",
    "        best_rmse = np.inf\n",
    "        scaler = GradScaler()\n",
    "        for epoch in range(1, Config.n_epoch + 1):\n",
    "            print(f'=== fold:{i_fold} epoch: {epoch}: training ===')\n",
    "            \n",
    "            metric_monitor = MetricMonitor()\n",
    "            stream = tqdm(train_loader)\n",
    "\n",
    "            for batch_idx, (images, dense, target) in enumerate(stream, start = 1):\n",
    "            #for batch_idx, (images, target) in enumerate(train_loader):\n",
    "                model.train()\n",
    "                #train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n",
    "                if Config.mixup_epoch >= epoch:\n",
    "                    images, target_a, target_b, lam = mixup_data(images, target.view(-1 ,1))\n",
    "                    images = images.to(device, dtype = torch.float)\n",
    "                    dense = dense.to(device, dtype = torch.float)\n",
    "                    target_a = target_a.to(device, dtype = torch.float)\n",
    "                    target_b = target_b.to(device, dtype = torch.float)\n",
    "                else:\n",
    "                    images = images.to(device, non_blocking = True).float()\n",
    "                    dense = dense.to(device, non_blocking = True).float()\n",
    "                    target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(): # mixed precision\n",
    "                    output = model(images, dense)\n",
    "\n",
    "                    if Config.mixup_epoch >= epoch:\n",
    "                        loss = mixup_criterion(criterion, output, target_a, target_b, lam)\n",
    "                    else:\n",
    "                        loss = criterion(output, target)\n",
    "                rmse_score = usr_rmse_score(output, target)\n",
    "                metric_monitor.update('Loss', loss.item())\n",
    "                metric_monitor.update('RMSE', rmse_score)\n",
    "                stream.set_description(f'Epoch: {epoch:02}. Train. {metric_monitor}')\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if (scheduler is not None) & (Config.scheduler_name != 'ReduceOnPlateauLR') :\n",
    "                    scheduler.step()\n",
    "            \n",
    "                if ( ( ( batch_idx % Config.steps_per_epoch == 0) & (epoch >= Config.epoch_step_valid) ) | ( batch_idx == len(train_loader) ) ):\n",
    "                    valid_targets, preds = valid_fn(y_valid, X_valid_paths, X_valid_dense, model, criterion, epoch)\n",
    "                    valid_rmse = round(mean_squared_error(valid_targets, preds, squared=False), 3)\n",
    "                    print(f'epoch: {epoch}, batch: {batch_idx}/{len(train_loader)}, valid rmse: {valid_rmse}')\n",
    "                    if Config.scheduler_name == 'ReduceOnPlateauLR':\n",
    "                        scheduler.step(valid_rmse)\n",
    "\n",
    "                    if valid_rmse < best_rmse:\n",
    "                        best_rmse = valid_rmse\n",
    "                        model_name = Config.model_path\n",
    "                        torch.save(model.state_dict(), f'{Config.model_dir}/{model_name}_fold{i_fold}.pth')\n",
    "                        print(\"saved model.\")\n",
    "                        _oof_df = pd.DataFrame(data={'Id': valid_ids, 'pred':preds, 'fold': i_fold, 'Pawpularity':valid_targets}, index=valid_idx)\n",
    "\n",
    "        del model, output, train_loader, train_dataset\n",
    "        gc.collect()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        oof_df = pd.concat([oof_df, _oof_df])\n",
    "    return oof_df.sort_values('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train_df['Id'].values\n",
    "filepaths = train_df['file_path'].values\n",
    "dense = train_df[Config.dense_features].values\n",
    "targets = train_df['Pawpularity'].values /100\n",
    "num_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n",
    "target_bins = pd.cut(targets, bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac13e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = training_loop(filepaths, dense, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4401ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_loop(filepaths, dense, targets):\n",
    "    skf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\n",
    "    oof_df = pd.DataFrame()\n",
    "    for i_fold, (train_idx, valid_idx) in enumerate(skf.split(filepaths, target_bins)):\n",
    "        print(f'=== fold {i_fold}: validation ===')\n",
    "        \"\"\"\n",
    "        separate valid data \n",
    "        \"\"\"\n",
    "        X_valid_paths = filepaths[valid_idx]\n",
    "        X_valid_dense = dense[valid_idx]\n",
    "        y_valid = targets[valid_idx]\n",
    "        valid_ids = ids[valid_idx]\n",
    "        \"\"\"\n",
    "        instantiate model, cost function and optimizer\n",
    "        \"\"\"\n",
    "        model = PetNet()\n",
    "        model_name = f'{Config.model_dir}/{Config.model_path}_fold{i_fold}.pth'\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        model = model.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        epoch = 0\n",
    "        valid_targets, preds = tta_fn(y_valid, X_valid_paths, X_valid_dense, model, criterion, epoch)\n",
    "        valid_rmse = round(mean_squared_error(valid_targets, preds, squared=False), 3)\n",
    "        _oof_df = pd.DataFrame(data={'Id': valid_ids, 'pred':preds, 'fold': i_fold, 'Pawpularity':valid_targets}, index=valid_idx)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        oof_df = pd.concat([oof_df, _oof_df])\n",
    "    return oof_df.sort_values('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8335557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def notta_loop(filepaths,targets):\n",
    "    skf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\n",
    "    oof_df = pd.DataFrame()\n",
    "    for i_fold, (train_idx, valid_idx) in enumerate(skf.split(filepaths, target_bins)):\n",
    "        print(f'=== fold {i_fold}: validation ===')\n",
    "        \"\"\"\n",
    "        separate valid data \n",
    "        \"\"\"\n",
    "        X_valid_paths = filepaths[valid_idx]\n",
    "        #X_valid_dense = dense[valid_idx]\n",
    "        y_valid = targets[valid_idx]\n",
    "        valid_ids = ids[valid_idx]\n",
    "        \"\"\"\n",
    "        instantiate model, cost function and optimizer\n",
    "        \"\"\"\n",
    "        model = PetNet(model_arch=Config.model_name, pretrained_path=Config.model_filepath)\n",
    "        model_name = f'convnext_large_22k_1k_384_fold{i_fold}.pth'\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        model = model.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        epoch = 0\n",
    "        valid_targets, preds = valid_fn(y_valid, X_valid_paths, model, criterion, epoch)\n",
    "        valid_rmse = round(mean_squared_error(valid_targets, preds, squared=False), 3)\n",
    "        _oof_df = pd.DataFrame(data={'Id': valid_ids, 'pred':preds, 'fold': i_fold, 'Pawpularity':valid_targets}, index=valid_idx)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        oof_df = pd.concat([oof_df, _oof_df])\n",
    "    return oof_df.sort_values('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Config.tta:\n",
    "#     oof_tta_df = tta_loop(filepaths, dense, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oof_df = notta_loop(filepaths, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff60b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no TTA\n",
    "for i in range(Config.n_fold):\n",
    "    rmse_oof(oof_df, i)\n",
    "rmse_oof(oof_df)\n",
    "oof_df.to_csv('oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(oof_df['Pawpularity'].values, alpha = 0.4, color = 'b', label = 'target', bins = 50)\n",
    "pred_bins = int((np.max(oof_df['pred'].values) - np.min(oof_df['pred'].values)) //2)\n",
    "plt.hist(oof_df['pred'].values, alpha = 0.4, color = 'g', label = 'prediction', bins = pred_bins)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with TTA\n",
    "for i in range(Config.n_fold):\n",
    "    rmse_oof(oof_tta_df, i)\n",
    "rmse_oof(oof_tta_df)\n",
    "oof_tta_df.to_csv('oof_tta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c60915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(oof_tta_df['Pawpularity'].values, alpha = 0.4, color = 'b', label = 'target', bins = 50)\n",
    "tta_pred_bins = int((np.max(oof_tta_df['pred'].values) - np.min(oof_tta_df['pred'].values)) //2)\n",
    "plt.hist(oof_df['pred'].values, alpha = 0.4, color = 'g', label = 'prediction', bins = tta_pred_bins)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9d3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84589a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
